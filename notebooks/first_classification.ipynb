{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/raian/anaconda3/envs/tensorflow/lib/python3.5/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<module 'deepleeo.networks.fcn' from '../src/deepleeo/networks/fcn.py'>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import os\n",
    "import sys\n",
    "import skimage\n",
    "import pylab as plt\n",
    "from importlib import reload\n",
    "\n",
    "sys.path.insert(0, '../src')\n",
    "import deepleeo.dataset.data_augment as dtaug\n",
    "import deepleeo.dataset.utils as dsutils\n",
    "from deepleeo.networks import fcn\n",
    "\n",
    "reload(dtaug)\n",
    "reload(dsutils)\n",
    "reload(fcn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load input Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_DIR = os.path.join(os.path.abspath(os.path.dirname(\"__file__\")), '../', 'data_real', 'generated')\n",
    "DATASET_FILE = os.path.join(DATA_DIR, 'samples_dataset.npz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data Loaded:\n",
      "  -> Images:  5000\n",
      "  -> Labels:  5000\n",
      "  -> Classes:  4\n",
      "Images shape:  (128, 128, 3)\n",
      "Labels shape:  (128, 128, 1)\n"
     ]
    }
   ],
   "source": [
    "dataset = np.load(DATASET_FILE)\n",
    "\n",
    "print(\"Data Loaded:\")\n",
    "print(\"  -> Images: \", len(dataset[\"images\"]))\n",
    "print(\"  -> Labels: \", len(dataset[\"labels\"]))\n",
    "print(\"  -> Classes: \", len(dataset[\"classes\"]))\n",
    "\n",
    "print(\"Images shape: \", dataset[\"images\"][0].shape)\n",
    "print(\"Labels shape: \", dataset[\"labels\"][0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plt.figure(figsize=(4,4))\n",
    "#img_plt = skimage.img_as_float(dataset[\"images\"][0][:,:,[5, 4, 3]]).astype(np.float32)\n",
    "#img_plt = dataset[\"images\"][0][:,:,[5, 4, 3]]\n",
    "#plt.imshow(img_plt)\n",
    "#plt.axis('off')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Perform Data Augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data Augmentation Applied:\n",
      "  -> Images:  (35000, 128, 128, 3)\n",
      "  -> Labels:  (35000, 128, 128, 1)\n"
     ]
    }
   ],
   "source": [
    "angles = [90, 180, 270]\n",
    "rotated_imgs = dtaug.rotate_images(dataset[\"images\"], angles)\n",
    "flipped_imgs = dtaug.flip_images(dataset[\"images\"])\n",
    "\n",
    "new_dataset = {}\n",
    "new_dataset[\"images\"] = np.concatenate((dataset[\"images\"], rotated_imgs))\n",
    "new_dataset[\"images\"] = np.concatenate((new_dataset[\"images\"], flipped_imgs))\n",
    "\n",
    "rotated_lbls = dtaug.rotate_images(dataset[\"labels\"], angles)\n",
    "flipped_lbls = dtaug.flip_images(dataset[\"labels\"])\n",
    "\n",
    "new_dataset[\"labels\"] = np.concatenate((dataset[\"labels\"], rotated_lbls))\n",
    "new_dataset[\"labels\"] = np.concatenate((new_dataset[\"labels\"], flipped_lbls))\n",
    "\n",
    "new_dataset[\"classes\"] = dataset[\"classes\"]\n",
    "\n",
    "print(\"Data Augmentation Applied:\")\n",
    "print(\"  -> Images: \", new_dataset[\"images\"].shape)\n",
    "print(\"  -> Labels: \", new_dataset[\"labels\"].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Split dataset between train, test and validation data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Splitted dataset:\n",
      "  -> Train images:  (24500, 128, 128, 3)\n",
      "  -> Test images:  (10500, 128, 128, 3)\n",
      "  -> Validation images:  (0, 128, 128, 3)\n",
      "  -> Train Labels:  (24500, 128, 128, 1)\n",
      "  -> Test Labels:  (10500, 128, 128, 1)\n",
      "  -> Validation Labels:  (0, 128, 128, 1)\n"
     ]
    }
   ],
   "source": [
    "train_images, test_images, valid_images, train_labels, test_labels, valid_labels = dsutils.split_dataset(new_dataset)\n",
    "\n",
    "print(\"Splitted dataset:\")\n",
    "print(\"  -> Train images: \", train_images.shape)\n",
    "print(\"  -> Test images: \", test_images.shape)\n",
    "print(\"  -> Validation images: \", valid_images.shape)\n",
    "print(\"  -> Train Labels: \", train_labels.shape)\n",
    "print(\"  -> Test Labels: \", test_labels.shape)\n",
    "print(\"  -> Validation Labels: \", valid_labels.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train the Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using default config.\n",
      "INFO:tensorflow:Using config: {'_save_checkpoints_secs': 600, '_keep_checkpoint_every_n_hours': 10000, '_model_dir': '/home/raian/doutorado/DeepLeEO/notebooks/../data_real/generated', '_task_id': 0, '_session_config': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f7b616b1208>, '_is_chief': True, '_num_worker_replicas': 1, '_tf_random_seed': None, '_save_checkpoints_steps': None, '_log_step_count_steps': 100, '_train_distribute': None, '_evaluation_master': '', '_master': '', '_num_ps_replicas': 0, '_device_fn': None, '_save_summary_steps': 100, '_service': None, '_global_id_in_cluster': 0, '_task_type': 'worker', '_keep_checkpoint_max': 5}\n",
      "INFO:tensorflow:Calling model_fn.\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "No gradients provided for any variable, check your graph for ops that do not support gradients, between variables [\"<tf.Variable 'Layer_1_1/conv2d/kernel:0' shape=(3, 3, 3, 64) dtype=float32_ref>\", \"<tf.Variable 'Layer_1_1/conv2d/bias:0' shape=(64,) dtype=float32_ref>\", \"<tf.Variable 'Layer_1_1/batch_normalization/gamma:0' shape=(64,) dtype=float32_ref>\", \"<tf.Variable 'Layer_1_1/batch_normalization/beta:0' shape=(64,) dtype=float32_ref>\", \"<tf.Variable 'Layer_1_2/conv2d/kernel:0' shape=(3, 3, 64, 64) dtype=float32_ref>\", \"<tf.Variable 'Layer_1_2/conv2d/bias:0' shape=(64,) dtype=float32_ref>\", \"<tf.Variable 'Layer_1_2/batch_normalization/gamma:0' shape=(64,) dtype=float32_ref>\", \"<tf.Variable 'Layer_1_2/batch_normalization/beta:0' shape=(64,) dtype=float32_ref>\", \"<tf.Variable 'Layer_2_1/conv2d/kernel:0' shape=(3, 3, 64, 128) dtype=float32_ref>\", \"<tf.Variable 'Layer_2_1/conv2d/bias:0' shape=(128,) dtype=float32_ref>\", \"<tf.Variable 'Layer_2_1/batch_normalization/gamma:0' shape=(128,) dtype=float32_ref>\", \"<tf.Variable 'Layer_2_1/batch_normalization/beta:0' shape=(128,) dtype=float32_ref>\", \"<tf.Variable 'Layer_2_2/conv2d/kernel:0' shape=(3, 3, 128, 128) dtype=float32_ref>\", \"<tf.Variable 'Layer_2_2/conv2d/bias:0' shape=(128,) dtype=float32_ref>\", \"<tf.Variable 'Layer_2_2/batch_normalization/gamma:0' shape=(128,) dtype=float32_ref>\", \"<tf.Variable 'Layer_2_2/batch_normalization/beta:0' shape=(128,) dtype=float32_ref>\", \"<tf.Variable 'Layer_3_1/conv2d/kernel:0' shape=(3, 3, 128, 256) dtype=float32_ref>\", \"<tf.Variable 'Layer_3_1/conv2d/bias:0' shape=(256,) dtype=float32_ref>\", \"<tf.Variable 'Layer_3_1/batch_normalization/gamma:0' shape=(256,) dtype=float32_ref>\", \"<tf.Variable 'Layer_3_1/batch_normalization/beta:0' shape=(256,) dtype=float32_ref>\", \"<tf.Variable 'Layer_3_2/conv2d/kernel:0' shape=(3, 3, 256, 256) dtype=float32_ref>\", \"<tf.Variable 'Layer_3_2/conv2d/bias:0' shape=(256,) dtype=float32_ref>\", \"<tf.Variable 'Layer_3_2/batch_normalization/gamma:0' shape=(256,) dtype=float32_ref>\", \"<tf.Variable 'Layer_3_2/batch_normalization/beta:0' shape=(256,) dtype=float32_ref>\", \"<tf.Variable 'Layer_3_3/conv2d/kernel:0' shape=(3, 3, 256, 256) dtype=float32_ref>\", \"<tf.Variable 'Layer_3_3/conv2d/bias:0' shape=(256,) dtype=float32_ref>\", \"<tf.Variable 'Layer_3_3/batch_normalization/gamma:0' shape=(256,) dtype=float32_ref>\", \"<tf.Variable 'Layer_3_3/batch_normalization/beta:0' shape=(256,) dtype=float32_ref>\", \"<tf.Variable 'Layer_4_1/conv2d/kernel:0' shape=(3, 3, 256, 512) dtype=float32_ref>\", \"<tf.Variable 'Layer_4_1/conv2d/bias:0' shape=(512,) dtype=float32_ref>\", \"<tf.Variable 'Layer_4_1/batch_normalization/gamma:0' shape=(512,) dtype=float32_ref>\", \"<tf.Variable 'Layer_4_1/batch_normalization/beta:0' shape=(512,) dtype=float32_ref>\", \"<tf.Variable 'Layer_4_2/conv2d/kernel:0' shape=(3, 3, 512, 512) dtype=float32_ref>\", \"<tf.Variable 'Layer_4_2/conv2d/bias:0' shape=(512,) dtype=float32_ref>\", \"<tf.Variable 'Layer_4_2/batch_normalization/gamma:0' shape=(512,) dtype=float32_ref>\", \"<tf.Variable 'Layer_4_2/batch_normalization/beta:0' shape=(512,) dtype=float32_ref>\", \"<tf.Variable 'Layer_4_3/conv2d/kernel:0' shape=(3, 3, 512, 512) dtype=float32_ref>\", \"<tf.Variable 'Layer_4_3/conv2d/bias:0' shape=(512,) dtype=float32_ref>\", \"<tf.Variable 'Layer_4_3/batch_normalization/gamma:0' shape=(512,) dtype=float32_ref>\", \"<tf.Variable 'Layer_4_3/batch_normalization/beta:0' shape=(512,) dtype=float32_ref>\", \"<tf.Variable 'Layer_5_1/conv2d/kernel:0' shape=(3, 3, 512, 512) dtype=float32_ref>\", \"<tf.Variable 'Layer_5_1/conv2d/bias:0' shape=(512,) dtype=float32_ref>\", \"<tf.Variable 'Layer_5_1/batch_normalization/gamma:0' shape=(512,) dtype=float32_ref>\", \"<tf.Variable 'Layer_5_1/batch_normalization/beta:0' shape=(512,) dtype=float32_ref>\", \"<tf.Variable 'Layer_5_2/conv2d/kernel:0' shape=(3, 3, 512, 512) dtype=float32_ref>\", \"<tf.Variable 'Layer_5_2/conv2d/bias:0' shape=(512,) dtype=float32_ref>\", \"<tf.Variable 'Layer_5_2/batch_normalization/gamma:0' shape=(512,) dtype=float32_ref>\", \"<tf.Variable 'Layer_5_2/batch_normalization/beta:0' shape=(512,) dtype=float32_ref>\", \"<tf.Variable 'Layer_5_3/conv2d/kernel:0' shape=(3, 3, 512, 512) dtype=float32_ref>\", \"<tf.Variable 'Layer_5_3/conv2d/bias:0' shape=(512,) dtype=float32_ref>\", \"<tf.Variable 'Layer_5_3/batch_normalization/gamma:0' shape=(512,) dtype=float32_ref>\", \"<tf.Variable 'Layer_5_3/batch_normalization/beta:0' shape=(512,) dtype=float32_ref>\", \"<tf.Variable 'Layer_fc6/conv2d/kernel:0' shape=(7, 7, 512, 4096) dtype=float32_ref>\", \"<tf.Variable 'Layer_fc6/conv2d/bias:0' shape=(4096,) dtype=float32_ref>\", \"<tf.Variable 'Layer_fc6/batch_normalization/gamma:0' shape=(4096,) dtype=float32_ref>\", \"<tf.Variable 'Layer_fc6/batch_normalization/beta:0' shape=(4096,) dtype=float32_ref>\", \"<tf.Variable 'Layer_fc7/conv2d/kernel:0' shape=(1, 1, 4096, 4096) dtype=float32_ref>\", \"<tf.Variable 'Layer_fc7/conv2d/bias:0' shape=(4096,) dtype=float32_ref>\", \"<tf.Variable 'Layer_fc7/batch_normalization/gamma:0' shape=(4096,) dtype=float32_ref>\", \"<tf.Variable 'Layer_fc7/batch_normalization/beta:0' shape=(4096,) dtype=float32_ref>\", \"<tf.Variable 'score_layer/kernel:0' shape=(1, 1, 4096, 21) dtype=float32_ref>\", \"<tf.Variable 'score_layer/bias:0' shape=(21,) dtype=float32_ref>\", \"<tf.Variable 'upconvuc/kernel:0' shape=(128, 128, 21, 21) dtype=float32_ref>\", \"<tf.Variable 'upconvuc/bias:0' shape=(21,) dtype=float32_ref>\"] and loss Tensor(\"softmax_cross_entropy_loss/value:0\", shape=(), dtype=float32).",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-44-db66a822bb2b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m }\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0mfcn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfcn_train\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_images\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_images\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhyper_params\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDATA_DIR\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/doutorado/DeepLeEO/src/deepleeo/networks/fcn.py\u001b[0m in \u001b[0;36mfcn_train\u001b[0;34m(train_imgs, test_imgs, train_labels, test_labels, hyper_params, output_dir)\u001b[0m\n\u001b[1;32m    118\u001b[0m     \u001b[0;31m# batch_images = tf.expand_dims(images, 0)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    119\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 120\u001b[0;31m     \u001b[0mtrain_results\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_fn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrain_input\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msteps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mhyper_params\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"epochs\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhooks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlogging_hook\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    121\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    122\u001b[0m     test_input = tf.estimator.inputs.numpy_input_fn(x={\"data\": test_imgs},\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow/lib/python3.5/site-packages/tensorflow/python/estimator/estimator.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, input_fn, hooks, steps, max_steps, saving_listeners)\u001b[0m\n\u001b[1;32m    364\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    365\u001b[0m       \u001b[0msaving_listeners\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_check_listeners_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msaving_listeners\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 366\u001b[0;31m       \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_train_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msaving_listeners\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    367\u001b[0m       \u001b[0mlogging\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Loss for final step: %s.'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    368\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow/lib/python3.5/site-packages/tensorflow/python/estimator/estimator.py\u001b[0m in \u001b[0;36m_train_model\u001b[0;34m(self, input_fn, hooks, saving_listeners)\u001b[0m\n\u001b[1;32m   1117\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_train_model_distributed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msaving_listeners\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1118\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1119\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_train_model_default\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msaving_listeners\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1120\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1121\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_train_model_default\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msaving_listeners\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow/lib/python3.5/site-packages/tensorflow/python/estimator/estimator.py\u001b[0m in \u001b[0;36m_train_model_default\u001b[0;34m(self, input_fn, hooks, saving_listeners)\u001b[0m\n\u001b[1;32m   1130\u001b[0m       \u001b[0mworker_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_hooks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1131\u001b[0m       estimator_spec = self._call_model_fn(\n\u001b[0;32m-> 1132\u001b[0;31m           features, labels, model_fn_lib.ModeKeys.TRAIN, self.config)\n\u001b[0m\u001b[1;32m   1133\u001b[0m       return self._train_with_estimator_spec(estimator_spec, worker_hooks,\n\u001b[1;32m   1134\u001b[0m                                              \u001b[0mhooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mglobal_step_tensor\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow/lib/python3.5/site-packages/tensorflow/python/estimator/estimator.py\u001b[0m in \u001b[0;36m_call_model_fn\u001b[0;34m(self, features, labels, mode, config)\u001b[0m\n\u001b[1;32m   1105\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1106\u001b[0m     \u001b[0mlogging\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Calling model_fn.'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1107\u001b[0;31m     \u001b[0mmodel_fn_results\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_model_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1108\u001b[0m     \u001b[0mlogging\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Done calling model_fn.'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1109\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/doutorado/DeepLeEO/src/deepleeo/networks/fcn.py\u001b[0m in \u001b[0;36mfcn32_VGG_description\u001b[0;34m(features, labels, params, mode, config)\u001b[0m\n\u001b[1;32m     85\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     86\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontrol_dependencies\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mupdate_ops\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 87\u001b[0;31m         \u001b[0mtrain_op\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mminimize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mglobal_step\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_global_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     88\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     89\u001b[0m     eval_summary_hook = tf.train.SummarySaverHook(save_steps=1,\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow/lib/python3.5/site-packages/tensorflow/python/training/optimizer.py\u001b[0m in \u001b[0;36mminimize\u001b[0;34m(self, loss, global_step, var_list, gate_gradients, aggregation_method, colocate_gradients_with_ops, name, grad_loss)\u001b[0m\n\u001b[1;32m    404\u001b[0m           \u001b[0;34m\"No gradients provided for any variable, check your graph for ops\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    405\u001b[0m           \u001b[0;34m\" that do not support gradients, between variables %s and loss %s.\"\u001b[0m \u001b[0;34m%\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 406\u001b[0;31m           ([str(v) for _, v in grads_and_vars], loss))\n\u001b[0m\u001b[1;32m    407\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    408\u001b[0m     return self.apply_gradients(grads_and_vars, global_step=global_step,\n",
      "\u001b[0;31mValueError\u001b[0m: No gradients provided for any variable, check your graph for ops that do not support gradients, between variables [\"<tf.Variable 'Layer_1_1/conv2d/kernel:0' shape=(3, 3, 3, 64) dtype=float32_ref>\", \"<tf.Variable 'Layer_1_1/conv2d/bias:0' shape=(64,) dtype=float32_ref>\", \"<tf.Variable 'Layer_1_1/batch_normalization/gamma:0' shape=(64,) dtype=float32_ref>\", \"<tf.Variable 'Layer_1_1/batch_normalization/beta:0' shape=(64,) dtype=float32_ref>\", \"<tf.Variable 'Layer_1_2/conv2d/kernel:0' shape=(3, 3, 64, 64) dtype=float32_ref>\", \"<tf.Variable 'Layer_1_2/conv2d/bias:0' shape=(64,) dtype=float32_ref>\", \"<tf.Variable 'Layer_1_2/batch_normalization/gamma:0' shape=(64,) dtype=float32_ref>\", \"<tf.Variable 'Layer_1_2/batch_normalization/beta:0' shape=(64,) dtype=float32_ref>\", \"<tf.Variable 'Layer_2_1/conv2d/kernel:0' shape=(3, 3, 64, 128) dtype=float32_ref>\", \"<tf.Variable 'Layer_2_1/conv2d/bias:0' shape=(128,) dtype=float32_ref>\", \"<tf.Variable 'Layer_2_1/batch_normalization/gamma:0' shape=(128,) dtype=float32_ref>\", \"<tf.Variable 'Layer_2_1/batch_normalization/beta:0' shape=(128,) dtype=float32_ref>\", \"<tf.Variable 'Layer_2_2/conv2d/kernel:0' shape=(3, 3, 128, 128) dtype=float32_ref>\", \"<tf.Variable 'Layer_2_2/conv2d/bias:0' shape=(128,) dtype=float32_ref>\", \"<tf.Variable 'Layer_2_2/batch_normalization/gamma:0' shape=(128,) dtype=float32_ref>\", \"<tf.Variable 'Layer_2_2/batch_normalization/beta:0' shape=(128,) dtype=float32_ref>\", \"<tf.Variable 'Layer_3_1/conv2d/kernel:0' shape=(3, 3, 128, 256) dtype=float32_ref>\", \"<tf.Variable 'Layer_3_1/conv2d/bias:0' shape=(256,) dtype=float32_ref>\", \"<tf.Variable 'Layer_3_1/batch_normalization/gamma:0' shape=(256,) dtype=float32_ref>\", \"<tf.Variable 'Layer_3_1/batch_normalization/beta:0' shape=(256,) dtype=float32_ref>\", \"<tf.Variable 'Layer_3_2/conv2d/kernel:0' shape=(3, 3, 256, 256) dtype=float32_ref>\", \"<tf.Variable 'Layer_3_2/conv2d/bias:0' shape=(256,) dtype=float32_ref>\", \"<tf.Variable 'Layer_3_2/batch_normalization/gamma:0' shape=(256,) dtype=float32_ref>\", \"<tf.Variable 'Layer_3_2/batch_normalization/beta:0' shape=(256,) dtype=float32_ref>\", \"<tf.Variable 'Layer_3_3/conv2d/kernel:0' shape=(3, 3, 256, 256) dtype=float32_ref>\", \"<tf.Variable 'Layer_3_3/conv2d/bias:0' shape=(256,) dtype=float32_ref>\", \"<tf.Variable 'Layer_3_3/batch_normalization/gamma:0' shape=(256,) dtype=float32_ref>\", \"<tf.Variable 'Layer_3_3/batch_normalization/beta:0' shape=(256,) dtype=float32_ref>\", \"<tf.Variable 'Layer_4_1/conv2d/kernel:0' shape=(3, 3, 256, 512) dtype=float32_ref>\", \"<tf.Variable 'Layer_4_1/conv2d/bias:0' shape=(512,) dtype=float32_ref>\", \"<tf.Variable 'Layer_4_1/batch_normalization/gamma:0' shape=(512,) dtype=float32_ref>\", \"<tf.Variable 'Layer_4_1/batch_normalization/beta:0' shape=(512,) dtype=float32_ref>\", \"<tf.Variable 'Layer_4_2/conv2d/kernel:0' shape=(3, 3, 512, 512) dtype=float32_ref>\", \"<tf.Variable 'Layer_4_2/conv2d/bias:0' shape=(512,) dtype=float32_ref>\", \"<tf.Variable 'Layer_4_2/batch_normalization/gamma:0' shape=(512,) dtype=float32_ref>\", \"<tf.Variable 'Layer_4_2/batch_normalization/beta:0' shape=(512,) dtype=float32_ref>\", \"<tf.Variable 'Layer_4_3/conv2d/kernel:0' shape=(3, 3, 512, 512) dtype=float32_ref>\", \"<tf.Variable 'Layer_4_3/conv2d/bias:0' shape=(512,) dtype=float32_ref>\", \"<tf.Variable 'Layer_4_3/batch_normalization/gamma:0' shape=(512,) dtype=float32_ref>\", \"<tf.Variable 'Layer_4_3/batch_normalization/beta:0' shape=(512,) dtype=float32_ref>\", \"<tf.Variable 'Layer_5_1/conv2d/kernel:0' shape=(3, 3, 512, 512) dtype=float32_ref>\", \"<tf.Variable 'Layer_5_1/conv2d/bias:0' shape=(512,) dtype=float32_ref>\", \"<tf.Variable 'Layer_5_1/batch_normalization/gamma:0' shape=(512,) dtype=float32_ref>\", \"<tf.Variable 'Layer_5_1/batch_normalization/beta:0' shape=(512,) dtype=float32_ref>\", \"<tf.Variable 'Layer_5_2/conv2d/kernel:0' shape=(3, 3, 512, 512) dtype=float32_ref>\", \"<tf.Variable 'Layer_5_2/conv2d/bias:0' shape=(512,) dtype=float32_ref>\", \"<tf.Variable 'Layer_5_2/batch_normalization/gamma:0' shape=(512,) dtype=float32_ref>\", \"<tf.Variable 'Layer_5_2/batch_normalization/beta:0' shape=(512,) dtype=float32_ref>\", \"<tf.Variable 'Layer_5_3/conv2d/kernel:0' shape=(3, 3, 512, 512) dtype=float32_ref>\", \"<tf.Variable 'Layer_5_3/conv2d/bias:0' shape=(512,) dtype=float32_ref>\", \"<tf.Variable 'Layer_5_3/batch_normalization/gamma:0' shape=(512,) dtype=float32_ref>\", \"<tf.Variable 'Layer_5_3/batch_normalization/beta:0' shape=(512,) dtype=float32_ref>\", \"<tf.Variable 'Layer_fc6/conv2d/kernel:0' shape=(7, 7, 512, 4096) dtype=float32_ref>\", \"<tf.Variable 'Layer_fc6/conv2d/bias:0' shape=(4096,) dtype=float32_ref>\", \"<tf.Variable 'Layer_fc6/batch_normalization/gamma:0' shape=(4096,) dtype=float32_ref>\", \"<tf.Variable 'Layer_fc6/batch_normalization/beta:0' shape=(4096,) dtype=float32_ref>\", \"<tf.Variable 'Layer_fc7/conv2d/kernel:0' shape=(1, 1, 4096, 4096) dtype=float32_ref>\", \"<tf.Variable 'Layer_fc7/conv2d/bias:0' shape=(4096,) dtype=float32_ref>\", \"<tf.Variable 'Layer_fc7/batch_normalization/gamma:0' shape=(4096,) dtype=float32_ref>\", \"<tf.Variable 'Layer_fc7/batch_normalization/beta:0' shape=(4096,) dtype=float32_ref>\", \"<tf.Variable 'score_layer/kernel:0' shape=(1, 1, 4096, 21) dtype=float32_ref>\", \"<tf.Variable 'score_layer/bias:0' shape=(21,) dtype=float32_ref>\", \"<tf.Variable 'upconvuc/kernel:0' shape=(128, 128, 21, 21) dtype=float32_ref>\", \"<tf.Variable 'upconvuc/bias:0' shape=(21,) dtype=float32_ref>\"] and loss Tensor(\"softmax_cross_entropy_loss/value:0\", shape=(), dtype=float32)."
     ]
    }
   ],
   "source": [
    "reload(fcn)\n",
    "hyper_params = {\n",
    "    \"epochs\": 10,\n",
    "    \"batch_size\": 256,\n",
    "    \"learning_rate\": 0.0001,\n",
    "    \"class_names\": new_dataset[\"classes\"]\n",
    "}\n",
    "\n",
    "fcn.fcn_train(train_images, test_images, train_labels, test_labels, hyper_params, DATA_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
