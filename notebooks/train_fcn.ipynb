{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/raian/anaconda3/envs/tensorflow/lib/python3.5/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<module 'deepleeo.utils.geofunctions' from '../src/deepleeo/utils/geofunctions.py'>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import os\n",
    "import sys\n",
    "import skimage\n",
    "import pylab as plt\n",
    "from importlib import reload\n",
    "from datetime import datetime\n",
    "\n",
    "sys.path.insert(0, '../src')\n",
    "import deepleeo.dataset.data_augment as dtaug\n",
    "import deepleeo.dataset.utils as dsutils \n",
    "import deepleeo.utils.geofunctions as gf\n",
    "import deepleeo.networks.model_builder as mb\n",
    "from deepleeo.networks import fcn\n",
    "\n",
    "reload(dtaug)\n",
    "reload(dsutils)\n",
    "reload(fcn)\n",
    "reload(mb)\n",
    "reload(gf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load input Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DATA_DIR = os.path.join(os.path.abspath(os.path.dirname(\"__file__\")), '../', 'data_real', 'generated')\n",
    "# DATASET_FILE = os.path.join(DATA_DIR, 'samples_dataset_bin.npz')\n",
    "network = \"fcn32s\"\n",
    "DATA_DIR = \"/home/raian/doutorado/Dados/generated\"\n",
    "DATASET_FILE = os.path.join(DATA_DIR, 'dataset_286x286_2016.npz')#'dataset_1.npz')\n",
    "#TODO: Put network name here in the path\n",
    "#model_dir = os.path.join(DATA_DIR, 'tf_logs', \"test_FCN_%s\" % datetime.now().strftime('%d_%m_%Y-%H_%M_%S'))\n",
    "model_dir = \"/home/raian/doutorado/DeepLeEO/data_real/generated/tf_logs/test_debug\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# raster_path = os.path.join(DATA_DIR, \"..\", \"Landsat8_225064_17072016_R6G5B4_clip.tif\")\n",
    "raster_path = os.path.join(DATA_DIR, \"..\", \"mosaic_2016.tif\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data Loaded:\n",
      "  -> Images:  5000\n",
      "  -> Labels:  5000\n",
      "  -> Classes:  2\n",
      "Images shape:  (286, 286, 5)  - DType:  float32\n",
      "Labels shape:  (286, 286, 1)  - DType:  int32\n"
     ]
    }
   ],
   "source": [
    "dataset = np.load(DATASET_FILE)\n",
    "\n",
    "print(\"Data Loaded:\")\n",
    "print(\"  -> Images: \", len(dataset[\"images\"]))\n",
    "print(\"  -> Labels: \", len(dataset[\"labels\"]))\n",
    "print(\"  -> Classes: \", len(dataset[\"classes\"]))\n",
    "\n",
    "print(\"Images shape: \", dataset[\"images\"][0].shape, \" - DType: \", dataset[\"images\"][0].dtype)\n",
    "print(\"Labels shape: \", dataset[\"labels\"][0].shape, \" - DType: \", dataset[\"labels\"][0].dtype)\n",
    "# print(\"UNIQUE LABELS: \", np.unique(dataset[\"labels\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plt.figure(figsize=(4,4))\n",
    "#img_plt = skimage.img_as_float(dataset[\"images\"][0])\n",
    "#img_plt = dataset[\"images\"][0]\n",
    "#plt.imshow(img_plt)\n",
    "#plt.axis('off')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Perform Data Augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data Augmentation Applied:\n",
      "  -> Images:  (35000, 286, 286, 5)\n",
      "  -> Labels:  (35000, 286, 286, 1)\n"
     ]
    }
   ],
   "source": [
    "reload(dtaug)\n",
    "angles = [90, 180, 270]\n",
    "rotated_imgs = dtaug.rotate_images(dataset[\"images\"], angles)\n",
    "flipped_imgs = dtaug.flip_images(dataset[\"images\"])\n",
    "\n",
    "new_dataset = {}\n",
    "new_dataset[\"images\"] = np.concatenate((dataset[\"images\"], rotated_imgs))\n",
    "new_dataset[\"images\"] = np.concatenate((new_dataset[\"images\"], flipped_imgs))\n",
    "\n",
    "rotated_lbls = dtaug.rotate_images(dataset[\"labels\"], angles)\n",
    "flipped_lbls = dtaug.flip_images(dataset[\"labels\"])\n",
    "\n",
    "new_dataset[\"labels\"] = np.concatenate((dataset[\"labels\"], rotated_lbls))\n",
    "new_dataset[\"labels\"] = np.concatenate((new_dataset[\"labels\"], flipped_lbls)).astype(dtype=np.int32)\n",
    "\n",
    "new_dataset[\"classes\"] = dataset[\"classes\"]\n",
    "\n",
    "print(\"Data Augmentation Applied:\")\n",
    "print(\"  -> Images: \", new_dataset[\"images\"].shape)\n",
    "print(\"  -> Labels: \", new_dataset[\"labels\"].shape)\n",
    "\n",
    "#print(\"  -> Unique Images: \", np.unique(new_dataset[\"images\"]))\n",
    "# print(\"  -> Unique Labels: \", np.unique(new_dataset[\"labels\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Split dataset between train, test and validation data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Splitted dataset:\n",
      "  -> Train images:  (24500, 286, 286, 5)\n",
      "  -> Test images:  (10500, 286, 286, 5)\n",
      "  -> Validation images:  (0, 286, 286, 5)\n",
      "  -> Train Labels:  (24500, 286, 286, 1)\n",
      "  -> Test Labels:  (10500, 286, 286, 1)\n",
      "  -> Validation Labels:  (0, 286, 286, 1)\n"
     ]
    }
   ],
   "source": [
    "train_images, test_images, valid_images, train_labels, test_labels, valid_labels = dsutils.split_dataset(new_dataset)\n",
    "\n",
    "print(\"Splitted dataset:\")\n",
    "print(\"  -> Train images: \", train_images.shape)\n",
    "print(\"  -> Test images: \", test_images.shape)\n",
    "print(\"  -> Validation images: \", valid_images.shape)\n",
    "print(\"  -> Train Labels: \", train_labels.shape)\n",
    "print(\"  -> Test Labels: \", test_labels.shape)\n",
    "print(\"  -> Validation Labels: \", valid_labels.shape)\n",
    "\n",
    "# print(\"  -> UNIQUE TRAIN LABELS: \", np.unique(train_labels), \" - Type: \", train_labels.dtype)\n",
    "# print(\"  -> UNIQUE TEST LABELS: \", np.unique(test_labels), \" - Type: \", test_labels.dtype)\n",
    "# print(\"  -> UNIQUE VALIDATION LABELS: \", np.unique(valid_labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train the Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "    \"epochs\": 2,\n",
    "    \"batch_size\": 200,\n",
    "    \"learning_rate\": 0.0001,\n",
    "    \"class_names\": dataset[\"classes\"],\n",
    "    \"multi_gpu\": False\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From ../src/deepleeo/networks/model_builder.py:33: replicate_model_fn (from tensorflow.contrib.estimator.python.estimator.replicate_model_fn) is deprecated and will be removed after 2018-05-31.\n",
      "Instructions for updating:\n",
      "Please use `tf.contrib.distribute.MirroredStrategy` instead.\n",
      "INFO:tensorflow:Replicating the `model_fn` across ['/device:GPU:0', '/device:GPU:1', '/device:GPU:2', '/device:GPU:3'].  Variables are going to be placed on ['/CPU:0'].  Consolidation device is going to be /CPU:0.\n",
      "INFO:tensorflow:Using default config.\n",
      "INFO:tensorflow:Using config: {'_device_fn': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f9bb9c6da58>, '_is_chief': True, '_save_summary_steps': 100, '_keep_checkpoint_every_n_hours': 10000, '_num_worker_replicas': 1, '_num_ps_replicas': 0, '_service': None, '_model_dir': '/home/raian/doutorado/DeepLeEO/data_real/generated/tf_logs/test_debug', '_save_checkpoints_steps': None, '_session_config': None, '_save_checkpoints_secs': 600, '_master': '', '_train_distribute': None, '_log_step_count_steps': 100, '_keep_checkpoint_max': 5, '_evaluation_master': '', '_tf_random_seed': None, '_task_id': 0, '_task_type': 'worker', '_global_id_in_cluster': 0}\n",
      "===============================================\n",
      "Epoch  1\n",
      "---------------\n",
      "Training...\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "WARNING:tensorflow:From ../src/deepleeo/networks/../networks/layers.py:32: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with distribution=normal is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "`normal` is a deprecated alias for `truncated_normal`\n",
      "WARNING:tensorflow:From ../src/deepleeo/networks/../networks/fcn.py:115: TowerOptimizer.__init__ (from tensorflow.contrib.estimator.python.estimator.replicate_model_fn) is deprecated and will be removed after 2018-05-31.\n",
      "Instructions for updating:\n",
      "Please use `tf.contrib.distribute.MirroredStrategy` instead.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Saving checkpoints for 0 into /home/raian/doutorado/DeepLeEO/data_real/generated/tf_logs/test_debug/model.ckpt.\n",
      "INFO:tensorflow:\n",
      "INFO:tensorflow:loss = 0.95673, step = 0\n",
      "INFO:tensorflow: (34.135 sec)\n",
      "INFO:tensorflow: (31.765 sec)\n",
      "INFO:tensorflow: (32.257 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.757387\n",
      "INFO:tensorflow: (33.880 sec)\n",
      "INFO:tensorflow:loss = 0.8928589, step = 100 (132.035 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 123 into /home/raian/doutorado/DeepLeEO/data_real/generated/tf_logs/test_debug/model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 0.8716536.\n",
      "---------------\n",
      "Evaluating...\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2018-10-02-18:19:58\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from /home/raian/doutorado/DeepLeEO/data_real/generated/tf_logs/test_debug/model.ckpt-123\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Finished evaluation at 2018-10-02-18:20:43\n",
      "INFO:tensorflow:Saving dict for global step 123: accuracy = 0.007408965, global_step = 123, loss = 0.9236909\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 123: /home/raian/doutorado/DeepLeEO/data_real/generated/tf_logs/test_debug/model.ckpt-123\n",
      "===============================================\n",
      "Epoch  2\n",
      "---------------\n",
      "Training...\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from /home/raian/doutorado/DeepLeEO/data_real/generated/tf_logs/test_debug/model.ckpt-123\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Saving checkpoints for 123 into /home/raian/doutorado/DeepLeEO/data_real/generated/tf_logs/test_debug/model.ckpt.\n",
      "INFO:tensorflow:\n",
      "INFO:tensorflow:loss = 0.8782692, step = 123\n",
      "INFO:tensorflow: (35.334 sec)\n",
      "INFO:tensorflow: (32.647 sec)\n",
      "INFO:tensorflow: (32.517 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.747547\n",
      "INFO:tensorflow: (33.274 sec)\n",
      "INFO:tensorflow:loss = 0.8470864, step = 223 (133.774 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 246 into /home/raian/doutorado/DeepLeEO/data_real/generated/tf_logs/test_debug/model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 0.82885176.\n",
      "---------------\n",
      "Evaluating...\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2018-10-02-18:23:52\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from /home/raian/doutorado/DeepLeEO/data_real/generated/tf_logs/test_debug/model.ckpt-246\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Finished evaluation at 2018-10-02-18:24:27\n",
      "INFO:tensorflow:Saving dict for global step 246: accuracy = 0.0016749883, global_step = 246, loss = 0.87727433\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 246: /home/raian/doutorado/DeepLeEO/data_real/generated/tf_logs/test_debug/model.ckpt-246\n"
     ]
    }
   ],
   "source": [
    "reload(fcn)\n",
    "reload(mb)\n",
    "\n",
    "model = mb.ModelBuilder(network)\n",
    "model.train(train_images, test_images, train_labels, test_labels, params, model_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#fcn.fcn_evaluate(valid_images, valid_labels,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO: Verificar aqui. Seria necessário inverter x e y?\n",
    "def generate_sequential_chips(img_array, chip_size=128):\n",
    "    x_size, y_size, nbands = img_array.shape\n",
    "    \n",
    "    struct = {\"chips\":[], \"coords\":[]}\n",
    "    for x_start in range(0, x_size, chip_size):\n",
    "        x_end = x_start + chip_size\n",
    "        \n",
    "        if x_end > x_start:\n",
    "            x_end = x_size\n",
    "            x_start = x_end - chip_size\n",
    "        \n",
    "        for y_start in range(0, y_size, chip_size):\n",
    "            y_end = y_start + chip_size\n",
    "            \n",
    "            if y_end > y_size:\n",
    "                y_end = y_size\n",
    "                y_start = y_end - chip_size\n",
    "                \n",
    "            chip_array = img_array[x_start:x_end, y_start:y_end, :]\n",
    "            \n",
    "            struct[\"chips\"].append(chip_array)\n",
    "            struct[\"coords\"].append({\"x_start\": x_start, \"y_start\": y_start})\n",
    "        \n",
    "    return struct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import deepleeo.dataset.preprocessor as prep\n",
    "\n",
    "reload(gf)\n",
    "reload(prep)\n",
    "#raster_array = gf.load_image(raster_path, 0)\n",
    "#print(raster_path)\n",
    "\n",
    "preproc = prep.Preprocessor(raster_path, no_data=-9999)\n",
    "raster_array = preproc.standardize_image()\n",
    "chips = generate_sequential_chips(raster_array)\n",
    "\n",
    "print(len(chips[\"chips\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "reload(fcn)\n",
    "\n",
    "#trained_model = \"/home/raian/doutorado/DeepLeEO/data_real/generated/tf_logs/test_22_08_2018-20_24_36\"\n",
    "\n",
    "predictions = fcn.fcn_predict(chips[\"chips\"], params=params, model_dir=model_dir)\n",
    "out_pred = chips.copy()\n",
    "out_pred[\"chips\"] = predictions.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def discretize_values(data, numberClass, startValue = 0):\n",
    "    for clazz in range(startValue, (numberClass + 1) ):\n",
    "        if clazz == startValue:\n",
    "            classFilter = (data <= clazz + 0.5)\n",
    "        elif  clazz == numberClass:\n",
    "            classFilter = (data > clazz - 0.5)\n",
    "        else:\n",
    "            classFilter = np.logical_and(data > clazz - 0.5, data <= clazz + 0.5) \n",
    "        data[classFilter] = clazz\n",
    "\n",
    "    return data.astype(np.uint8)\n",
    "\n",
    "new_pred = []\n",
    "for chip in out_pred[\"chips\"]:\n",
    "    new_pred.append(discretize_values(chip, 2, 0))\n",
    "    \n",
    "out_pred[\"chips\"] = new_pred.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gdal\n",
    "import osr\n",
    "\n",
    "output_path = os.path.join(DATA_DIR, \"prediction.tiff\")\n",
    "\n",
    "def write_prediction(output_path, base_raster, pred_struct, output_format=\"GTiff\", dataType=gdal.GDT_UInt16):\n",
    "    driver = gdal.GetDriverByName(output_format)\n",
    "    base_ds = gdal.Open(base_raster)\n",
    "    \n",
    "    x_start, pixel_width, _, y_start, _, pixel_height = base_ds.GetGeoTransform()\n",
    "    x_size = base_ds.RasterXSize\n",
    "    y_size = base_ds.RasterYSize\n",
    "    \n",
    "    srs = osr.SpatialReference()\n",
    "    srs.ImportFromWkt(base_ds.GetProjectionRef())\n",
    "    \n",
    "    out_ds = driver.Create(output_path, x_size, y_size, 1, dataType)\n",
    "    out_ds.SetGeoTransform((x_start, pixel_width, 0, y_start, 0, pixel_height))\n",
    "    out_ds.SetProjection(srs.ExportToWkt())\n",
    "    out_band = out_ds.GetRasterBand(1)\n",
    "    \n",
    "    for idx in range(1, len(pred_struct[\"chips\"])):\n",
    "        chip = pred_struct[\"chips\"][idx]\n",
    "        chip = np.squeeze(chip)\n",
    "        out_band.WriteArray(chip, pred_struct[\"coords\"][idx][\"y_start\"], pred_struct[\"coords\"][idx][\"x_start\"])\n",
    "        \n",
    "    out_band.FlushCache()\n",
    "    \n",
    "write_prediction(output_path, raster_path, out_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_ds = gdal.Open(output_path)\n",
    "rarr = new_ds.ReadAsArray()\n",
    "\n",
    "print(np.unique(rarr))\n",
    "\n",
    "from deepleeo.utils import image\n",
    "reload(image)\n",
    "\n",
    "print(\"MIN: \", np.min(rarr))\n",
    "print(\"MAX: \", np.max(rarr))\n",
    "\n",
    "image.plot_image_histogram(rarr, title = \"prediction\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pylab as pl\n",
    "from matplotlib.colors import ListedColormap\n",
    "\n",
    "pl.figure(figsize=(10, 10))\n",
    "pl.title('Labels')\n",
    "print(\"Raster Shape:\", rarr.shape)\n",
    "\n",
    "colorMap = ListedColormap([\"red\", \"green\", \"blue\", \"yellow\"])\n",
    "pl.imshow(rarr, cmap=colorMap)\n",
    "cbar = pl.colorbar()\n",
    "cbar.ax.get_yaxis().set_ticks([])\n",
    "\n",
    "for j, lab in enumerate(new_dataset[\"classes\"]):\n",
    "    cbar.ax.text(1.5, (2 * j + 1) / 8, lab, ha='left')\n",
    "\n",
    "cbar.ax.get_yaxis().labelpad = 15\n",
    "#cbar.ax.set_yticklabels(class_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
