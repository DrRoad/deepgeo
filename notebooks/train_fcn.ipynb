{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/raian/anaconda3/envs/tensorflow/lib/python3.5/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<module 'deepgeo.common.geofunctions' from '../src/deepgeo/common/geofunctions.py'>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import os\n",
    "import sys\n",
    "from importlib import reload\n",
    "from datetime import datetime\n",
    "\n",
    "sys.path.insert(0, '../src')\n",
    "import deepgeo.dataset.data_augment as dtaug\n",
    "import deepgeo.dataset.utils as dsutils \n",
    "import deepgeo.common.geofunctions as gf\n",
    "import deepgeo.networks.model_builder as mb\n",
    "\n",
    "reload(dtaug)\n",
    "reload(dsutils)\n",
    "reload(mb)\n",
    "reload(gf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load input Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DATA_DIR = os.path.join(os.path.abspath(os.path.dirname('__file__')), '../', 'data_real', 'generated')\n",
    "network = 'unet'\n",
    "DATA_DIR = '/home/raian/doutorado/Dados/generated'\n",
    "# DATASET_FILE = os.path.join(DATA_DIR, 'new_dataset_286x286_timesstack-2013-2017.npz')\n",
    "DATASET = os.path.join(DATA_DIR, 'dataset_286x286_tmstk-2013-2017')\n",
    "\n",
    "class_names = ['no_data', 'not_deforestation', 'deforestation']\n",
    "# model_dir = os.path.join(DATA_DIR, 'tf_logs', network,\n",
    "#                          'test_%s_%s' % (network, datetime.now().strftime('%d_%m_%Y-%H_%M_%S')))\n",
    "model_dir = '/home/raian/doutorado/deepgeo/data_real/generated/tf_logs/test_debug'\n",
    "# model_dir = os.path.join(DATA_DIR, 'tf_logs', 'experiments', 'unet', 'test_unet_29_04_2019-12_51_06')\n",
    "train_tfrecord = os.path.join(DATASET, 'dataset_train.tfrecord')\n",
    "test_tfrecord = os.path.join(DATASET, 'dataset_test.tfrecord')\n",
    "val_tfrecord = os.path.join(DATASET, 'dataset_validation.tfrecord')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 8\r\n",
      "drwxr-xr-x 2 raian digits 4096 May 22 13:21 .\r\n",
      "drwxr-xr-x 3 raian digits 4096 Dec  7 19:52 ..\r\n"
     ]
    }
   ],
   "source": [
    "!rm -rf {model_dir}/*\n",
    "!ls -al {model_dir}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Split dataset between train, test and validation data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset = np.load(DATASET_FILE)\n",
    "\n",
    "# print(\"Data Loaded:\")\n",
    "# print(\"  -> Images: \", len(dataset[\"images\"]))\n",
    "# print(\"  -> Labels: \", len(dataset[\"labels\"]))\n",
    "# print(\"  -> Classes: \", len(dataset[\"classes\"]))\n",
    "\n",
    "# print(\"Images shape: \", dataset[\"images\"][0].shape, \" - DType: \", dataset[\"images\"][0].dtype)\n",
    "# print(\"Labels shape: \", dataset[\"labels\"][0].shape, \" - DType: \", dataset[\"labels\"][0].dtype)\n",
    "# print('Classes: ', dataset['classes'])\n",
    "# print(\"UNIQUE LABELS: \", np.unique(dataset[\"labels\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# train_images, test_images, valid_images, train_labels, test_labels, valid_labels = dsutils.split_dataset(dataset,\n",
    "#                                                                                                          perc_test=20,\n",
    "#                                                                                                          perc_val=20)\n",
    "\n",
    "# print(\"Splitted dataset:\")\n",
    "# print(\"  -> Train images: \", train_images.shape)\n",
    "# print(\"  -> Test images: \", test_images.shape)\n",
    "# print(\"  -> Validation images: \", valid_images.shape)\n",
    "# print(\"  -> Train Labels: \", train_labels.shape)\n",
    "# print(\"  -> Test Labels: \", test_labels.shape)\n",
    "# print(\"  -> Validation Labels: \", valid_labels.shape)\n",
    "# total_train_chips = train_images.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Perform Data Augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# angles = [90, 180, 270]\n",
    "# rotated_imgs = dtaug.rotate_images(train_images, angles)\n",
    "# flipped_imgs = dtaug.flip_images(train_images)\n",
    "\n",
    "# train_images = np.concatenate((train_images, rotated_imgs, flipped_imgs))\n",
    "# # train_images = np.concatenate((train_images, ))\n",
    "\n",
    "# rotated_lbls = dtaug.rotate_images(train_labels, angles)\n",
    "# flipped_lbls = dtaug.flip_images(train_labels)\n",
    "\n",
    "# train_labels = np.concatenate((train_labels, rotated_lbls, flipped_lbls))\n",
    "# # train_labels = np.concatenate((train_labels, )).astype(dtype=np.int32)\n",
    "\n",
    "# print('Data Augmentation Applied:')\n",
    "# print('  -> Train Images: ', train_images.shape)\n",
    "# print('  -> Train Labels: ', train_labels.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save to TFRecords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_progress(count, total):\n",
    "    # Percentage completion.\n",
    "    pct_complete = float(count) / total\n",
    "\n",
    "    # Status-message.\n",
    "    # Note the \\r which means the line should overwrite itself.\n",
    "    msg = \"\\r- Progress: {0:.1%}\".format(pct_complete)\n",
    "\n",
    "    # Print it.\n",
    "    sys.stdout.write(msg)\n",
    "    sys.stdout.flush()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def wrap_bytes(value):\n",
    "#     return tf.train.Feature(bytes_list=tf.train.BytesList(value=[value]))\n",
    "\n",
    "# def wrap_float(value):\n",
    "#     return tf.train.Feature(float_list=tf.train.FloatList(value=[value]))\n",
    "\n",
    "# def wrap_int64(value):\n",
    "#     return tf.train.Feature(int64_list=tf.train.Int64List(value=[value]))\n",
    "\n",
    "# def save_to_tfrecord(out_path, imgs, labels):\n",
    "#     with tf.python_io.TFRecordWriter(out_path) as writer:\n",
    "#         for i in range(imgs.shape[0]):\n",
    "#             img = imgs[i, :, :, :]\n",
    "#             lbl = labels[i, :, :, :]\n",
    "            \n",
    "#             height = img.shape[0]\n",
    "#             width = img.shape[1]\n",
    "#             channels = img.shape[2]\n",
    "            \n",
    "#             img_raw = img.tostring()\n",
    "#             lbl_raw = lbl.tostring()\n",
    "            \n",
    "#             feature = {'image': wrap_bytes(img_raw),\n",
    "#                        'label': wrap_bytes(lbl_raw),\n",
    "#                        'channels': wrap_int64(channels),\n",
    "#                        'height': wrap_int64(height),\n",
    "#                        'width': wrap_int64(width)}\n",
    "            \n",
    "#             example = tf.train.Example(features=tf.train.Features(feature=feature))\n",
    "#             writer.write(example.SerializeToString())\n",
    "\n",
    "# save_to_tfrecord(train_tfrecord, train_images, train_labels)\n",
    "# save_to_tfrecord(test_tfrecord, test_images, test_labels)\n",
    "# save_to_tfrecord(val_tfrecord, valid_images, valid_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Computing weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def compute_weights_mean_proportion(batch_array, classes, classes_zero=['no_data']):\n",
    "#     values, count = np.unique(batch_array, return_counts=True)\n",
    "#     count = [count[i] if classes[i] not in classes_zero else 0 for i in range(0, len(count))]\n",
    "#     total = sum(count)\n",
    "#     proportions = [i / total for i in count]\n",
    "#     mean_prop = sum(proportions)/ (len(proportions) - len(classes_zero))\n",
    "#     weights = [mean_prop / i if i != 0 else 0 for i in proportions]\n",
    "#     return weights\n",
    "\n",
    "\n",
    "# weights_train = compute_weights_mean_proportion(train_labels, dataset['classes'])\n",
    "# weights_eval = compute_weights_mean_proportion(test_labels, dataset['classes'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parsing \" /home/raian/doutorado/Dados/generated/dataset_286x286_tmstk-2013-2017/dataset_train.tfrecord \"\n",
      "Parsing \" /home/raian/doutorado/Dados/generated/dataset_286x286_tmstk-2013-2017/dataset_test.tfrecord \"\n"
     ]
    }
   ],
   "source": [
    "def parse(serialized):\n",
    "    features = {'label': tf.FixedLenFeature([], tf.string, default_value=''),\n",
    "                'height': tf.FixedLenFeature([], tf.int64, default_value=0),\n",
    "                'width': tf.FixedLenFeature([], tf.int64, default_value=0)}\n",
    "\n",
    "    parsed_features = tf.parse_single_example(serialized=serialized, features=features)\n",
    "    height = parsed_features['height']\n",
    "    width = parsed_features['width']\n",
    "\n",
    "    label = tf.decode_raw(parsed_features['label'], tf.int32)\n",
    "    label = tf.reshape(label, [height, width, 1])\n",
    "\n",
    "    return label\n",
    "\n",
    "def compute_weights_mean_proportion(tfrecord, classes, classes_zero=['no_data']):\n",
    "    tf.enable_eager_execution()\n",
    "    train_ds = tf.data.TFRecordDataset(tfrecord)\n",
    "    train_ds = train_ds.map(parse)\n",
    "    tot_count = [0] * len(classes)\n",
    "    for label in train_ds:\n",
    "        label = label.numpy()\n",
    "        unique, count = np.unique(label, return_counts=True)\n",
    "        for k, v in enumerate(unique):\n",
    "            if classes[v] not in classes_zero:\n",
    "                tot_count[v] += count[k]\n",
    "    total = sum(tot_count)\n",
    "    proportions = [i / total for i in tot_count]\n",
    "    mean_prop = sum(proportions)/ (len(proportions) - len(classes_zero))\n",
    "    weights = [mean_prop / i if i != 0 else 0 for i in proportions]\n",
    "    return weights\n",
    "    \n",
    "weights_train = compute_weights_mean_proportion(train_tfrecord, class_names, ['no_data'])\n",
    "weights_eval = compute_weights_mean_proportion(test_tfrecord, class_names, ['no_data'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 0.5028229179643342, 89.06084489828929]\n",
      "[0, 0.5028547403476658, 88.07363877398384]\n"
     ]
    }
   ],
   "source": [
    "# print(weights_train)\n",
    "# print(weights_eval)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train the Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "    'epochs': 1,\n",
    "    'batch_size': 40,\n",
    "    'chip_size': 286,\n",
    "    'bands': 10,\n",
    "    'filter_reduction': 0.5,\n",
    "    'learning_rate': 0.1,\n",
    "    'learning_rate_decay': True,\n",
    "    'decay_rate': 0.95,\n",
    "    'l2_reg_rate': 0.0005,\n",
    "    # 'var_scale_factor': 2.0,  # TODO: Put the initializer as parameter\n",
    "    'chips_tensorboard': 2,\n",
    "    # 'dropout_rate': 0.5,  # TODO: Put a bool parameter to apply or not Dropout\n",
    "    'fusion': 'early',\n",
    "    'loss_func': 'weighted_crossentropy',\n",
    "    'data_aug_ops': ['rot90', 'rot180', 'rot270', 'flip_left_right',\n",
    "                     'flip_up_down', 'flip_transpose'],\n",
    "    'class_weights': {'train': weights_train, 'eval': weights_eval},\n",
    "    'num_classes': len(class_names),\n",
    "    'class_names': ['no data', 'not deforestation', 'deforestation'],\n",
    "    'num_compositions': 2,\n",
    "    'bands_plot': [[1, 2, 3], [6, 7, 8]],\n",
    "    'Notes': 'Testing.'\n",
    "}\n",
    "reload(mb)\n",
    "model = mb.ModelBuilder(network)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From ../src/deepgeo/networks/../common/../networks/dataset_loader.py:77: tf_record_iterator (from tensorflow.python.lib.io.tf_record) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use eager execution and: \n",
      "`tf.data.TFRecordDataset(path)`\n",
      "\n",
      "WARNING: The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
      "For more information, please see:\n",
      "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
      "  * https://github.com/tensorflow/addons\n",
      "If you depend on functionality not listed there, please file an issue.\n",
      "\n",
      "INFO:tensorflow:Device is available but not used by distribute strategy: /device:CPU:0\n",
      "INFO:tensorflow:Device is available but not used by distribute strategy: /device:XLA_GPU:0\n",
      "INFO:tensorflow:Device is available but not used by distribute strategy: /device:XLA_GPU:1\n",
      "INFO:tensorflow:Device is available but not used by distribute strategy: /device:XLA_GPU:2\n",
      "INFO:tensorflow:Device is available but not used by distribute strategy: /device:XLA_GPU:3\n",
      "INFO:tensorflow:Device is available but not used by distribute strategy: /device:XLA_CPU:0\n",
      "INFO:tensorflow:Configured nccl all-reduce.\n",
      "INFO:tensorflow:Initializing RunConfig with distribution strategies.\n",
      "INFO:tensorflow:Not using Distribute Coordinator.\n",
      "INFO:tensorflow:Using config: {'_session_config': allow_soft_placement: true\n",
      "graph_options {\n",
      "  rewrite_options {\n",
      "    meta_optimizer_iterations: ONE\n",
      "  }\n",
      "}\n",
      ", '_keep_checkpoint_max': 5, '_evaluation_master': '', '_eval_distribute': None, '_is_chief': True, '_task_type': 'worker', '_device_fn': None, '_log_step_count_steps': 100, '_master': '', '_save_summary_steps': 100, '_task_id': 0, '_service': None, '_num_worker_replicas': 1, '_save_checkpoints_steps': None, '_tf_random_seed': None, '_save_checkpoints_secs': 600, '_keep_checkpoint_every_n_hours': 10000, '_num_ps_replicas': 0, '_protocol': None, '_train_distribute': <tensorflow.contrib.distribute.python.mirrored_strategy.MirroredStrategy object at 0x7f0d501a96d8>, '_distribute_coordinator_mode': None, '_experimental_distribute': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f0d501a9710>, '_model_dir': '/home/raian/doutorado/deepgeo/data_real/generated/tf_logs/test_debug', '_global_id_in_cluster': 0}\n",
      "INFO:tensorflow:Not using Distribute Coordinator.\n",
      "INFO:tensorflow:Running training and evaluation locally (non-distributed).\n",
      "INFO:tensorflow:Start train and evaluate loop. The evaluate will happen after every checkpoint. Checkpoint frequency is determined based on RunConfig arguments: save_checkpoints_steps None or save_checkpoints_secs 600.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "WARNING:tensorflow:From ../src/deepgeo/networks/../common/../networks/unet.py:23: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use keras.layers.conv2d instead.\n",
      "WARNING:tensorflow:From ../src/deepgeo/networks/../common/../networks/layers.py:19: batch_normalization (from tensorflow.python.layers.normalization) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use keras.layers.batch_normalization instead.\n",
      "WARNING:tensorflow:From ../src/deepgeo/networks/../common/../networks/layers.py:28: max_pooling2d (from tensorflow.python.layers.pooling) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use keras.layers.max_pooling2d instead.\n",
      "WARNING:tensorflow:From ../src/deepgeo/networks/../common/../networks/layers.py:46: conv2d_transpose (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use keras.layers.conv2d_transpose instead.\n",
      "WARNING:tensorflow:From ../src/deepgeo/networks/../common/../networks/loss_functions.py:37: softmax_cross_entropy_with_logits (from tensorflow.python.ops.nn_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "\n",
      "Future major versions of TensorFlow will allow gradients to flow\n",
      "into the labels input on backprop by default.\n",
      "\n",
      "See `tf.nn.softmax_cross_entropy_with_logits_v2`.\n",
      "\n",
      "WARNING:tensorflow:From /home/raian/anaconda3/envs/tensorflow/lib/python3.5/site-packages/tensorflow/python/ops/metrics_impl.py:526: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "WARNING:tensorflow:From /home/raian/anaconda3/envs/tensorflow/lib/python3.5/site-packages/tensorflow/contrib/metrics/python/metrics/classification.py:162: div (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Deprecated in favor of operator or tf.math.divide.\n",
      "WARNING:tensorflow:From /home/raian/anaconda3/envs/tensorflow/lib/python3.5/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "INFO:tensorflow:batch_all_reduce invoked for batches size = 92 with algorithm = nccl, num_packs = 1, agg_small_grads_max_bytes = 0 and agg_small_grads_max_group = 10\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Saving checkpoints for 0 into /home/raian/doutorado/deepgeo/data_real/generated/tf_logs/test_debug/model.ckpt.\n",
      "INFO:tensorflow:Initialize strategy\n",
      "INFO:tensorflow:loss = 0.9107379, step = 0\n",
      "INFO:tensorflow:accuracy = 0.3621375, auc_roc = 0.552119, cross_entropy = 1.0937864, f1_score = 0.49999997, learning_rate = 0.1, loss = 1.7164881\n",
      "INFO:tensorflow:global_step/sec: 1.3489\n",
      "INFO:tensorflow:loss = 0.3696627, step = 100 (74.138 sec)\n",
      "INFO:tensorflow:accuracy = 0.39898875, auc_roc = 0.56809795, cross_entropy = 1.0882057, f1_score = 0.49999997, learning_rate = 0.09927915, loss = 0.24297595 (74.129 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.39829\n",
      "INFO:tensorflow:loss = 0.30228883, step = 200 (41.694 sec)\n",
      "INFO:tensorflow:accuracy = 0.480195, auc_roc = 0.6510892, cross_entropy = 1.0293502, f1_score = 0.537956, learning_rate = 0.09856349, loss = 0.29941398 (41.694 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 206 into /home/raian/doutorado/deepgeo/data_real/generated/tf_logs/test_debug/model.ckpt.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2019-05-22T16:33:39Z\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "WARNING:tensorflow:From /home/raian/anaconda3/envs/tensorflow/lib/python3.5/site-packages/tensorflow/python/training/saver.py:1266: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use standard file APIs to check for files with this prefix.\n",
      "INFO:tensorflow:Restoring parameters from /home/raian/doutorado/deepgeo/data_real/generated/tf_logs/test_debug/model.ckpt-206\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:accuracy = 0.75716, auc_roc = 0.82151544, cross_entropy = 0.8010454, f1_score = 0.7616727, learning_rate = 0.09852072, loss = 26.44854\n",
      "INFO:tensorflow:Evaluation [10/100]\n",
      "INFO:tensorflow:Evaluation [20/100]\n",
      "INFO:tensorflow:Evaluation [30/100]\n",
      "INFO:tensorflow:Evaluation [40/100]\n",
      "INFO:tensorflow:Evaluation [50/100]\n",
      "INFO:tensorflow:Evaluation [60/100]\n",
      "INFO:tensorflow:Evaluation [70/100]\n",
      "INFO:tensorflow:Evaluation [80/100]\n",
      "INFO:tensorflow:Evaluation [90/100]\n",
      "INFO:tensorflow:Evaluation [100/100]\n",
      "INFO:tensorflow:Finished evaluation at 2019-05-22-16:34:29\n",
      "INFO:tensorflow:Saving dict for global step 206: eval_metrics/accuracy = 0.6692544, eval_metrics/auc_roc = 0.78824914, eval_metrics/cross_entropy = 0.8676007, eval_metrics/f1-score = 0.72279054, global_step = 206, loss = 36.053246\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 206: /home/raian/doutorado/deepgeo/data_real/generated/tf_logs/test_debug/model.ckpt-206\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Finalize strategy.\n",
      "INFO:tensorflow:Loss for final step: 0.28406376.\n"
     ]
    }
   ],
   "source": [
    "model.train(train_tfrecord, test_tfrecord, params, model_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'valid_images' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-15-2e9125815dbe>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalidate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalid_images\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalid_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_dir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'valid_images' is not defined"
     ]
    }
   ],
   "source": [
    "model.validate(valid_images, valid_labels, params, model_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
