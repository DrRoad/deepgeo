{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/raian/anaconda3/envs/tensorflow/lib/python3.5/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<module 'deepleeo.utils.geofunctions' from '../src/deepleeo/utils/geofunctions.py'>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import os\n",
    "import sys\n",
    "from importlib import reload\n",
    "from datetime import datetime\n",
    "\n",
    "sys.path.insert(0, '../src')\n",
    "import deepleeo.dataset.data_augment as dtaug\n",
    "import deepleeo.dataset.utils as dsutils \n",
    "import deepleeo.utils.geofunctions as gf\n",
    "import deepleeo.networks.model_builder as mb\n",
    "\n",
    "reload(dtaug)\n",
    "reload(dsutils)\n",
    "reload(mb)\n",
    "reload(gf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load input Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DATA_DIR = os.path.join(os.path.abspath(os.path.dirname(\"__file__\")), '../', 'data_real', 'generated')\n",
    "network = \"unet\"\n",
    "DATA_DIR = \"/home/raian/doutorado/Dados/generated\"\n",
    "DATASET_FILE = os.path.join(DATA_DIR, 'dataset_286x286_timesstack-2015-2016.npz')#'dataset_1.npz')\n",
    "\n",
    "# model_dir = os.path.join(DATA_DIR, 'tf_logs', \"test_%s_%s\" % (network, datetime.now().strftime('%d_%m_%Y-%H_%M_%S')))\n",
    "model_dir = \"/home/raian/doutorado/Dados/generated/tf_logs/test_debug\"\n",
    "# model_dir = os.path.join(DATA_DIR, 'tf_logs', 'test_fcn8s_11_12_2018-17_26_32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 8\r\n",
      "drwxr-xr-x  2 raian digits 4096 Mar 29 19:06 .\r\n",
      "drwxr-xr-x 15 raian digits 4096 Feb 22 22:26 ..\r\n"
     ]
    }
   ],
   "source": [
    "!rm -rf {model_dir}/*\n",
    "!ls -al {model_dir}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data Loaded:\n",
      "  -> Images:  5000\n",
      "  -> Labels:  5000\n",
      "  -> Classes:  2\n"
     ]
    }
   ],
   "source": [
    "dataset = np.load(DATASET_FILE)\n",
    "\n",
    "print(\"Data Loaded:\")\n",
    "print(\"  -> Images: \", len(dataset[\"images\"]))\n",
    "print(\"  -> Labels: \", len(dataset[\"labels\"]))\n",
    "print(\"  -> Classes: \", len(dataset[\"classes\"]))\n",
    "\n",
    "print(\"Images shape: \", dataset[\"images\"][0].shape, \" - DType: \", dataset[\"images\"][0].dtype)\n",
    "print(\"Labels shape: \", dataset[\"labels\"][0].shape, \" - DType: \", dataset[\"labels\"][0].dtype)\n",
    "# print(\"UNIQUE LABELS: \", np.unique(dataset[\"labels\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Perform Data Augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reload(dtaug)\n",
    "# new_dataset = {}\n",
    "# new_dataset[\"images\"] = dataset[\"images\"]\n",
    "# new_dataset[\"labels\"] = dataset[\"labels\"]\n",
    "\n",
    "# steps = 1000\n",
    "# num_chips = len(dataset[\"images\"])\n",
    "# for i in range(0, num_chips, steps):\n",
    "#     endstep = i + steps\n",
    "#     if endstep > num_chips:\n",
    "#         endstep = num_chips - 1\n",
    "    \n",
    "#     angles = [90, 180, 270]\n",
    "#     rotated_imgs = dtaug.rotate_images(dataset[\"images\"][i:endstep], angles)\n",
    "#     flipped_imgs = dtaug.flip_images(dataset[\"images\"][i:endstep])\n",
    "\n",
    "#     new_dataset[\"images\"] = np.concatenate((new_dataset[\"images\"], rotated_imgs))\n",
    "#     new_dataset[\"images\"] = np.concatenate((new_dataset[\"images\"], flipped_imgs))\n",
    "\n",
    "#     rotated_lbls = dtaug.rotate_images(dataset[\"labels\"][i:endstep], angles)\n",
    "#     flipped_lbls = dtaug.flip_images(dataset[\"labels\"][i:endstep])\n",
    "\n",
    "#     new_dataset[\"labels\"] = np.concatenate((new_dataset[\"labels\"], rotated_lbls))\n",
    "#     new_dataset[\"labels\"] = np.concatenate((new_dataset[\"labels\"], flipped_lbls)).astype(dtype=np.int32)\n",
    "\n",
    "# new_dataset[\"classes\"] = dataset[\"classes\"]\n",
    "\n",
    "# print(\"Data Augmentation Applied:\")\n",
    "# print(\"  -> Images: \", new_dataset[\"images\"].shape)\n",
    "# print(\"  -> Labels: \", new_dataset[\"labels\"].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Split dataset between train, test and validation data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train_images, test_images, valid_images, train_labels, test_labels, valid_labels = dsutils.split_dataset(dataset)\n",
    "\n",
    "print(\"Splitted dataset:\")\n",
    "print(\"  -> Train images: \", train_images.shape)\n",
    "print(\"  -> Test images: \", test_images.shape)\n",
    "print(\"  -> Validation images: \", valid_images.shape)\n",
    "print(\"  -> Train Labels: \", train_labels.shape)\n",
    "print(\"  -> Test Labels: \", test_labels.shape)\n",
    "print(\"  -> Validation Labels: \", valid_labels.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train the Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "    'epochs': 3,\n",
    "    'batch_size': 100,\n",
    "    'learning_rate': 0.001,\n",
    "    'l2_reg_rate': 0.5,\n",
    "    'var_scale_factor': 2.0,\n",
    "    'chips_tensorboard': 2,\n",
    "    'dropout_rate': 0.5,\n",
    "    'fusion': 'early',\n",
    "    'num_classes': len(dataset[\"classes\"]),\n",
    "    'bands_plot': [6,7,8]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "model = mb.ModelBuilder(network)\n",
    "model.train(train_images, test_images, train_labels, test_labels, params, model_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#fcn.fcn_evaluate(valid_images, valid_labels,)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
